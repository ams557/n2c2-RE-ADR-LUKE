{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import permutations, combinations\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import os,sys, io\n",
    "from io import FileIO\n",
    "import fnmatch\n",
    "import re, string\n",
    "import csv\n",
    "from utils.text_utils import *\n",
    "from pathlib import Path\n",
    "from transformers import LukeTokenizer\n",
    "\n",
    "# from experiments.n2c2.twenty18.task2.RE.config import *\n",
    "# from src.preprocessing import *\n",
    "# from datamodules.LUKE.datamoduleRE import *\n",
    "# from models.pretrained.LUKE import *\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "# import wandb\n",
    "# wandb.login(key=WANDB_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import permutations, combinations\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import os,sys, io\n",
    "from io import FileIO\n",
    "import re, fnmatch\n",
    "import csv\n",
    "from utils.text_utils import *\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "class InvalidAnnotationError(ValueError):\n",
    "    \"\"\"Error raised for directories where format is invalid \n",
    "    (eg. number of .ann files is not equal to the number of .txt files)\n",
    "    - Taken from RELEX\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def BRATtoDFconvert(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Function to convert directory from BRAT format to dataframe usable for LUKE for entity pair classification\n",
    "    Args:\n",
    "        path (string): The directory to convert.\n",
    "    Returns:\n",
    "        df: Dataframe with the following items::\n",
    "            end_idx: Position of the end of the relation w/in the entire text\n",
    "            entity_spans: The starting end ending positions of the HEAD & TAIL entities normalized to the sentence length the relation is from\n",
    "            match: The substring that comprises the relation\n",
    "            original_article: The full-text of file that the relation is in\n",
    "            sentence: The text of the sentence(s) that the relation is in\n",
    "            start_idx: Position of the start of the relation w/in the entire text\n",
    "            string_id: The label of the relation\n",
    "    \"\"\"\n",
    "    annotations = {\n",
    "        'entities' : pd.DataFrame(), \n",
    "        'relations' : pd.DataFrame()\n",
    "    }\n",
    "    # only grab files that are relevant to BRAT annotations\n",
    "    files = [file for file in os.listdir(path) if file.endswith('.ann')][1:2]\n",
    "    # sort files \n",
    "    files.sort(key=lambda f : os.path.splitext(f)[1])\n",
    "    for file in files:\n",
    "        annotation = read_file(path + '/' + file)\n",
    "        annotations['entities'] = pd.concat([annotations['entities'],process_annotation(path + file)['entities']],ignore_index=True) \n",
    "        annotations['relations'] = pd.concat([annotations['relations'],process_annotation(path + file)['relations']],ignore_index=True)\n",
    "    \n",
    "    candidates = pd.merge(annotations['entities'], annotations['entities'], on='file', suffixes=['1','2']).query(\"tag1 != tag2 and (entity_name1 == 'Drug') and entity_name1 != entity_name2\")\n",
    "    candidates.rename(columns={'entity_span2' : 'relation_start', 'entity_span1' : 'relation_end', 'entity2' : 'start_entity', 'entity1' : 'end_entity'},inplace=True)\n",
    "    candidates.drop(columns=['entity_name1', 'tag1','tag2','entity_name2'],inplace=True)\n",
    "    candidates = generate_df(df=candidates,path=path)\n",
    "\n",
    "    if not annotations['relations'].empty:\n",
    "        annotations['relations'].drop(columns=['tag'],inplace=True)\n",
    "        # Inner join relations dataframe to entities sub-dataframe on the relatio start in the correct file\n",
    "        relations = pd.merge(annotations['relations'],annotations['entities'][['file','tag','entity_span','entity']],left_on=['file','relation_start'],right_on=['file','tag'])\n",
    "        relations.drop(columns=['tag','relation_start'],inplace=True)\n",
    "        relations.rename(columns={'entity_span' : 'relation_start','entity' : 'start_entity', 'relation_name' : 'string_id'},inplace=True)\n",
    "\n",
    "        # Inner join the combined dataframe to get the relation end within the correct file\n",
    "        relations = pd.merge(relations,annotations['entities'][['file','tag','entity_span','entity']],left_on=['file','relation_end'],right_on=['file','tag'])\n",
    "        relations.drop(columns=['tag','relation_end'],inplace=True)\n",
    "        relations.rename(columns={'entity_span' : 'relation_end', 'entity' :'end_entity'},inplace=True)\n",
    "\n",
    "\n",
    "        relations = generate_df(df=relations,path=path)\n",
    "        cols = ['end_idx', 'match','original_article','sentences','start_idx']\n",
    "\n",
    "        candidates = pd.merge(candidates,relations[cols+['string_id']],on=cols,how=\"left\")\n",
    "        candidates.fillna({'string_id': 'Unrelated'}, inplace=True)\n",
    "\n",
    "    return candidates\n",
    "\n",
    "def grab_entity_info(line: list[str,str,str]) -> pd.DataFrame:\n",
    "    \"\"\"Function list of entity info from a line of BRAT format to dataframe usable for LUKE for entity pair classification\n",
    "    Args:\n",
    "        line (list[str,str,str]): The annotation line (for entities [prefixed T])\n",
    "    Returns:\n",
    "        Dataframe with the following items::\n",
    "            tag: The entity tag w/in a file (eg. T1 for the first entity in that file)\n",
    "            entity_name: The entity (type) in a line\n",
    "            entity_span: A list of the start & end index of an entity in a text file\n",
    "            entity : The entity mention\n",
    "    \"\"\"\n",
    "    tags = line[1].split(\" \") # this middle segment contains the entity label, the entity start & the entity end\n",
    "    entity_name = str(tags[0])\n",
    "    entity_start = int(tags[1])\n",
    "    entity_end = int(tags[-1])\n",
    "    return pd.DataFrame({\n",
    "        'tag' : line[0], \n",
    "        'entity_name' : entity_name, \n",
    "        'entity_span' : [np.array([entity_start, entity_end],dtype=object)], \n",
    "        'entity' : line[-1]\n",
    "    },index=[0],dtype=object)\n",
    "\n",
    "def grab_relation_info(line: list[str,str,str]) -> pd.DataFrame:\n",
    "    \"\"\"Function list of relation info from a line of BRAT format to dataframe usable for LUKE for entity pair classification\n",
    "    Args:\n",
    "        line (list[str,str,str]): The annotation line (for relations [prefixed R])\n",
    "    Returns:\n",
    "        Dataframe with the following items::\n",
    "            tag: The relation tag w/in a file (eg. R1 for the first relation in that file)\n",
    "            relation_name: The relation (type)\n",
    "            relation_start: The starting index of the relation\n",
    "            relation_end: The ending index of the relation\n",
    "    \"\"\"\n",
    "    tags = line[1].split(\" \")\n",
    "    assert len(tags) == 3, \"Incorrect relation format\" # from RELEX preprocessing\n",
    "    relation_name = tags[0]\n",
    "    relation_start = tags[1].split(':')[1]\n",
    "    relation_end = tags[2].split(':')[1]\n",
    "    return pd.DataFrame({\n",
    "        'tag' : line[0], \n",
    "        'relation_name' : relation_name, \n",
    "        'relation_start' : relation_start, \n",
    "        'relation_end' : relation_end\n",
    "    },index=[0],dtype=object)\n",
    "\n",
    "def generate_df(df: pd.DataFrame, path: str) -> pd.DataFrame:\n",
    "    df['entities'] = [[start,end] for start, end in zip(df['relation_start'],df['relation_end'])]\n",
    "    # df.drop(columns=['relation_start','relation_end'],inplace=True)\n",
    "    df['original_article'] = [read_file(path + str(file) + '.txt') for file in df['file']]\n",
    "    df.drop(columns='file',inplace=True)\n",
    "    # get the start idx by finding the smallest starting index of an entity in a relation\n",
    "    df['start_idx'] = df.apply(lambda row : find_smallest_first_element(row, 'relation_start', 'relation_end'), axis=1)\n",
    "\n",
    "    # get the end idx by finding the largest starting index of an entity in a relation\n",
    "    df['end_idx'] = df.apply(lambda row : find_largest_last_element(row, 'relation_start', 'relation_end'), axis=1)\n",
    "\n",
    "    # using the starting and ending indices of the relation get the match\n",
    "    df['match'] = df.apply(lambda row : row['original_article'][row['start_idx']:row['end_idx']],axis=1)\n",
    "\n",
    "    # grab all the sentences relevant to a single relation\n",
    "    df['sentences'] = df.apply(lambda row : find_sentences_around_match(text=row['original_article'],begin=row['start_idx'],end=row['end_idx']),axis=1)\n",
    "\n",
    "    # find the beginning index of a sentence\n",
    "    df['BOS_idx'] = df.apply(lambda row : find_BOS_index(row['original_article'],row['start_idx']),axis=1)\n",
    "\n",
    "    # normalize the entity spans to the length of the group of sentences that they are found in\n",
    "    df['entity_spans'] = df.apply(lambda row : np.array([norm_list(row['relation_start'],row['BOS_idx']),norm_list(row['relation_end'],row['BOS_idx'])],dtype=object),axis=1)\n",
    "    cols = ['end_idx', 'entities','entity_spans','match','original_article','sentences','start_idx']\n",
    "    if 'string_id' in df.columns:\n",
    "        cols.append('string_id')\n",
    "    \n",
    "    df = df[cols].astype(object)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    return df\n",
    "\n",
    "def process_annotation(path: str) -> dict({str : pd.DataFrame, str : pd.DataFrame}):\n",
    "    \"\"\"Function to convert relation line (prefixed w/ R) from BRAT format to dataframe usable for LUKE for entity pair classification\n",
    "    Args:\n",
    "        line (string): Tab delimited line\n",
    "    Returns:\n",
    "        annotations (dict): Dictionary of entity & relation dataframes\n",
    "    \n",
    "    - Adapted from RELEX\n",
    "    \"\"\"\n",
    "    annotations = {\n",
    "        'entities' : pd.DataFrame(), \n",
    "        'relations' : pd.DataFrame()\n",
    "    }\n",
    "    with open(path,'r') as file:\n",
    "        annotation = file.readlines()\n",
    "    for line in annotation:\n",
    "        line = line.strip()\n",
    "        if line == \"\" or line.startswith(\"#\"): # ignore lines that are empty or start w/ `#` (borrowed from RELEX)\n",
    "            continue\n",
    "        if \"\\t\" not in line:\n",
    "            InvalidAnnotationError(\"Line chunks in ANN files must be separated by tabs (See BRAT Guidelines).\")\n",
    "        line = line.split(\"\\t\")\n",
    "        if line[0][0] == 'T':\n",
    "            annotations['entities'] = pd.concat([annotations['entities'],grab_entity_info(line)],ignore_index=True)\n",
    "            annotations['entities']['file'] = str(os.path.split(path)[1].replace(\".ann\",\"\"))\n",
    "        if line[0][0] == 'R':\n",
    "            annotations['relations'] = pd.concat([annotations['relations'],grab_relation_info(line)],ignore_index=True)\n",
    "            annotations['relations']['file'] = str(os.path.split(path)[1].replace(\".ann\",\"\"))\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(TRAIN_DIR).mkdir(parents=True, exist_ok=True)\n",
    "Path(TEST_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dataset = {\n",
    "    'train' : BRATtoDFconvert('../datasets/n2c2/2018/task2/RE/train/'\n",
    "    # 'test'  : BRATtoDFconvert('../datasets/n2c2/2018/task2/RE/test/'\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dataset['train']\n",
    "train_df\n",
    "# entities = train_df['entities']\n",
    "# entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('sentences:', 'min =',str(dataset['train'].sentences.str.len().min()) + ',','max =', str(dataset['train'].sentences.str.len().max()))\n",
    "print('matches:','min =',str(dataset['train'].match.str.len().min()) + ',','max =', str(dataset['train'].match.str.len().max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = dict()\n",
    "for idx, label in enumerate(dataset['train'].string_id.value_counts().index):\n",
    "  id2label[idx] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(id2label.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {v:k for k,v in id2label.items()}\n",
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'].string_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'].sentences.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LukeTokenizer.from_pretrained(\"studio-ousia/luke-base\", task=\"entity_pair_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=RANDOM_STATE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=RANDOM_STATE, shuffle=True)\n",
    "train_dataset = RelationExtractionDataset(data=train_df,tokenizer=tokenizer,label2id=label2id)\n",
    "valid_dataset = RelationExtractionDataset(data=val_df,tokenizer=tokenizer,label2id=label2id)\n",
    "test_dataset = RelationExtractionDataset(data=dataset['test'],tokenizer=tokenizer,label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=2)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "tokenizer.decode(batch[\"input_ids\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label[batch[\"label\"][1].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(valid_dataloader))\n",
    "labels = batch[\"label\"]\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LUKE(\n",
    "    num_labels=len(label2id),\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    label2id=label2id)\n",
    "del batch[\"label\"]\n",
    "outputs = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "initial_loss = criterion(outputs.logits, labels)\n",
    "print(\"Initial loss:\", initial_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger = WandbLogger(name='LUKE-N2C2-RE', project='LUKE')\n",
    "# for early stopping, see https://pytorch-lightning.readthedocs.io/en/1.0.0/early_stopping.html?highlight=early%20stopping\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=2,\n",
    "    strict=False,\n",
    "    verbose=False,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    # max_epochs=1,\n",
    "    logger=wandb_logger, \n",
    "    callbacks=[EarlyStopping(monitor='val_loss')],\n",
    "    )\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = LUKE.load_from_checkpoint(checkpoint_path=\"LUKE/checkpoints/epoch=3-step=7699.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loaded_model.to(device)\n",
    "\n",
    "predictions_total = []\n",
    "labels_total = []\n",
    "for batch in tqdm(test_dataloader):\n",
    "    # get the inputs;\n",
    "    labels = batch[\"label\"]\n",
    "    del batch[\"label\"]\n",
    "\n",
    "    # move everything to the GPU\n",
    "    for k,v in batch.items():\n",
    "      batch[k] = batch[k].to(device)\n",
    "\n",
    "    # forward pass\n",
    "    outputs = loaded_model.model(**batch)\n",
    "    logits = outputs.logits\n",
    "    predictions = logits.argmax(-1)\n",
    "    predictions_total.extend(predictions.tolist())\n",
    "    labels_total.extend(labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy on test set:\", accuracy_score(labels_total, predictions_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df.iloc[0].sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "text = test_df.iloc[idx].sentence\n",
    "entity_spans = test_df.iloc[idx].entity_spans  # character-based entity spans\n",
    "entity_spans = [tuple(x) for x in entity_spans]\n",
    "\n",
    "inputs = tokenizer(text, entity_spans=entity_spans, return_tensors=\"pt\")\n",
    "\n",
    "outputs = loaded_model.model(**inputs)\n",
    "logits = outputs.logits\n",
    "predicted_class_idx = logits.argmax(-1).item()\n",
    "print(\"Sentence:\", text)\n",
    "print(\"Ground truth label:\", test_df.iloc[idx].string_id)\n",
    "print(\"Predicted class idx:\", id2label[predicted_class_idx])\n",
    "print(\"Confidence:\", F.softmax(logits, -1).max().item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
