{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import permutations, combinations\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import os,sys, io\n",
    "from io import FileIO\n",
    "import re, fnmatch\n",
    "import csv\n",
    "from utils.helpers import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'DATA/'\n",
    "Path(DATA_DIR).mkdir(parents=True, exist_ok=True)\n",
    "TRAINING_DIR = DATA_DIR + 'train/training_20180910/'\n",
    "Path(TRAINING_DIR).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvalidAnnotationError(ValueError):\n",
    "    pass\n",
    "\n",
    "def BRATtoDFconvert(path):\n",
    "    annotations = {\n",
    "        'entities' : pd.DataFrame(), \n",
    "        'relations' : pd.DataFrame()\n",
    "    }\n",
    "    files = [file for file in os.listdir(path) if file.endswith('.ann')]\n",
    "    files.sort(key=lambda f : os.path.splitext(f)[1])\n",
    "    for file in files:\n",
    "        annotation = read_file(path + '/' + file)\n",
    "        annotations['entities'] = pd.concat([annotations['entities'],process_annotation(path + file)['entities']],ignore_index=True) \n",
    "        annotations['relations'] = pd.concat([annotations['relations'],process_annotation(path + file)['relations']],ignore_index=True)\n",
    "    annotations['relations'].drop(columns=['tag'],inplace=True)\n",
    "    df = pd.merge(annotations['relations'],annotations['entities'][['file','tag','entity_span','entity']],left_on=['file','relation_start'],right_on=['file','tag'])\n",
    "    df.drop(columns=['tag','relation_start'],inplace=True)\n",
    "    df.rename(columns={'entity_span' : 'relation_start','entity' : 'start_entity'},inplace=True)\n",
    "    df = pd.merge(df,annotations['entities'][['file','tag','entity_span','entity']],left_on=['file','relation_end'],right_on=['file','tag'])\n",
    "    df.drop(columns=['tag','relation_end'],inplace=True)\n",
    "    df.rename(columns={'entity_span' : 'relation_end', 'entity' :'end_entity'},inplace=True)\n",
    "    range_df = range(len(df))\n",
    "    df['entities'] = [[df['start_entity'],df['end_entity']] for i in range_df]\n",
    "    # df['entities'] = df.apply(lambda row : [row['start_entity'],row['end_entity']], axis=1)\n",
    "    df.drop(columns=['start_entity','end_entity'],inplace=True)\n",
    "    df['original_article'] = df.apply(lambda row : read_file(TRAINING_DIR + row['file'] + '.txt'), axis=1)\n",
    "    df.drop(columns='file')\n",
    "    df['start_idx'] = df.apply(lambda row : find_smallest_first_element(row, 'relation_start', 'relation_end'), axis=1)\n",
    "    df['end_idx'] = df.apply(lambda row : find_largest_last_element(row, 'relation_start', 'relation_end'), axis=1)\n",
    "    df['match'] = df.apply(lambda row : row['original_article'][row['start_idx']:row['end_idx']],axis=1)\n",
    "    df['sentences'] = df.apply(lambda row : find_sentences_around_match(row['original_article'],row['start_idx'],row['end_idx']),axis=1)\n",
    "    df['BOS_idx'] = df.apply(lambda row : find_BOS_index(row['original_article'],row['start_idx']),axis=1)\n",
    "    df['entity_spans'] = df.apply(lambda row : combine_and_norm_lists(row['relation_start'], row['relation_end'],row['BOS_idx']), axis=1)\n",
    "    return df\n",
    "\n",
    "def grab_entity_info(line):\n",
    "    tags = line[1].split(\" \")\n",
    "    entity_name = str(tags[0])\n",
    "    entity_start = int(tags[1])\n",
    "    entity_end = int(tags[-1])\n",
    "    df = pd.DataFrame({'tag' : line[0], 'entity_name' : entity_name, 'entity_span' : [[entity_start, entity_end]], 'entity' : line[-1]},index=[0],dtype=object)\n",
    "    # df['entity_span'] = \n",
    "    return df\n",
    "    \n",
    "    # return (entity_name, [entity_start, entity_end], line[-1])\n",
    "\n",
    "def grab_relation_info(line):\n",
    "    tags = line[1].split(\" \")\n",
    "    assert len(tags) == 3, \"Incorrect relation format\"\n",
    "    relation_name = tags[0]\n",
    "    relation_start = tags[1].split(':')[1]\n",
    "    relation_end = tags[2].split(':')[1]\n",
    "    return pd.DataFrame({'tag' : line[0], 'relation_name' : relation_name, 'relation_start' : relation_start, 'relation_end' : relation_end},index=[0],dtype=object)\n",
    "\n",
    "def process_annotation(path):\n",
    "    annotations = {\n",
    "        'entities' : pd.DataFrame(), \n",
    "        'relations' : pd.DataFrame()\n",
    "    }\n",
    "    with open(path,'r') as file:\n",
    "        annotation = file.readlines()\n",
    "    for line in annotation:\n",
    "        line = line.strip()\n",
    "        annotations['entities']['file'] = os.path.split(path)[1].replace(\".ann\",\"\")\n",
    "        if line == \"\" or line.startswith(\"#\"):\n",
    "            continue\n",
    "        if \"\\t\" not in line:\n",
    "            InvalidAnnotationError(\"Line chunks in ANN files must be separated by tabs (See BRAT Guidelines).\")\n",
    "        line = line.split(\"\\t\")\n",
    "        if line[0][0] == 'T':\n",
    "            # print(f\"{os.path.split(path)[1].replace(\".ann\",\"\")}\")\n",
    "            annotations['entities'] = pd.concat([annotations['entities'],grab_entity_info(line)],ignore_index=True)\n",
    "        if line[0][0] == 'R':\n",
    "            # print(os.path.split(path)[1].replace(\".ann\",\"\"))\n",
    "            annotations['relations'] = pd.concat([annotations['relations'],grab_relation_info(line)],ignore_index=True)\n",
    "        annotations['relations']['file'] = os.path.split(path)[1].replace(\".ann\",\"\")\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = BRATtoDFconvert(TRAINING_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BOS_idx'].isna().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
