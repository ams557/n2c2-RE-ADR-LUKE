{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import permutations, combinations\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import os,sys, io\n",
    "from io import FileIO\n",
    "import fnmatch\n",
    "import re, string\n",
    "import csv\n",
    "from utils.helpers import *\n",
    "from config import *\n",
    "from preprocessing import *\n",
    "from dataset import *\n",
    "from model import *\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "import wandb\n",
    "wandb.login(key=WANDB_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'train' : BRATtoDFconvert(TRAIN_DIR),\n",
    "    'test'  : BRATtoDFconvert(TEST_DIR)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('sentences:', 'min =',str(dataset['train'].sentences.str.len().min()) + ',','max =', str(dataset['train'].sentences.str.len().max()))\n",
    "print('matches:','min =',str(dataset['train'].match.str.len().min()) + ',','max =', str(dataset['train'].match.str.len().max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = dict()\n",
    "for idx, label in enumerate(dataset['train'].string_id.value_counts().index):\n",
    "  id2label[idx] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {v:k for k,v in id2label.items()}\n",
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'].sentences.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LukeTokenizer.from_pretrained(\"studio-ousia/luke-base\", task=\"entity_pair_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=RANDOM_STATE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=RANDOM_STATE, shuffle=True)\n",
    "train_dataset = RelationExtractionDataset(data=train_df,tokenizer=tokenizer,label2id=label2id)\n",
    "valid_dataset = RelationExtractionDataset(data=val_df,tokenizer=tokenizer,label2id=label2id)\n",
    "test_dataset = RelationExtractionDataset(data=dataset['test'],tokenizer=tokenizer,label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=2)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "tokenizer.decode(batch[\"input_ids\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label[batch[\"label\"][1].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(valid_dataloader))\n",
    "labels = batch[\"label\"]\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LUKE(\n",
    "    num_labels=len(label2id),\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    label2id=label2id)\n",
    "del batch[\"label\"]\n",
    "outputs = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "initial_loss = criterion(outputs.logits, labels)\n",
    "print(\"Initial loss:\", initial_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger = WandbLogger(name='LUKE-N2C2-RE', project='LUKE')\n",
    "# for early stopping, see https://pytorch-lightning.readthedocs.io/en/1.0.0/early_stopping.html?highlight=early%20stopping\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=2,\n",
    "    strict=False,\n",
    "    verbose=False,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    logger=wandb_logger, \n",
    "    callbacks=[EarlyStopping(monitor='val_loss')],\n",
    "    )\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = LUKE.load_from_checkpoint(checkpoint_path=\"LUKE/checkpoints/epoch=3-step=7699.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loaded_model.to(device)\n",
    "\n",
    "predictions_total = []\n",
    "labels_total = []\n",
    "for batch in tqdm(test_dataloader):\n",
    "    # get the inputs;\n",
    "    labels = batch[\"label\"]\n",
    "    del batch[\"label\"]\n",
    "\n",
    "    # move everything to the GPU\n",
    "    for k,v in batch.items():\n",
    "      batch[k] = batch[k].to(device)\n",
    "\n",
    "    # forward pass\n",
    "    outputs = loaded_model.model(**batch)\n",
    "    logits = outputs.logits\n",
    "    predictions = logits.argmax(-1)\n",
    "    predictions_total.extend(predictions.tolist())\n",
    "    labels_total.extend(labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy on test set:\", accuracy_score(labels_total, predictions_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df.iloc[0].sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "text = test_df.iloc[idx].sentence\n",
    "entity_spans = test_df.iloc[idx].entity_spans  # character-based entity spans\n",
    "entity_spans = [tuple(x) for x in entity_spans]\n",
    "\n",
    "inputs = tokenizer(text, entity_spans=entity_spans, return_tensors=\"pt\")\n",
    "\n",
    "outputs = loaded_model.model(**inputs)\n",
    "logits = outputs.logits\n",
    "predicted_class_idx = logits.argmax(-1).item()\n",
    "print(\"Sentence:\", text)\n",
    "print(\"Ground truth label:\", test_df.iloc[idx].string_id)\n",
    "print(\"Predicted class idx:\", id2label[predicted_class_idx])\n",
    "print(\"Confidence:\", F.softmax(logits, -1).max().item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
